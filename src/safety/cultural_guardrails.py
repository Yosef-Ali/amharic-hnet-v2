import re
from typing import Dict, List, Tuple, Set
from dataclasses import dataclass


@dataclass
class CulturalViolation:
    """Represents a cultural safety violation."""
    term: str
    violation_type: str
    context: str
    severity: str  # 'low', 'medium', 'high'


class AmharicCulturalGuardrails:
    """
    Cultural safety system for Amharic language generation.
    Prevents inappropriate associations with sacred, cultural, and sensitive terms.
    """
    
    def __init__(self):
        # Sacred and religious terms that require respectful treatment
        self.sacred_terms = {
            "·â°·äì": "·ã®·ä¢·âµ·ãÆ·åµ·ã´ ·â£·àÖ·àã·ãä ·àõ·àÖ·â†·à´·ãä ·à•·à≠·ãì·âµ",  # Coffee ceremony - social ritual
            "·àò·àµ·âÄ·àç": "·âÖ·ã±·àµ ·àù·àç·ä≠·âµ",  # Cross - sacred symbol
            "·âÄ·ã≥·àõ·ãä": "·â≥·à™·ä´·ãä ·äï·åâ·à•",  # Kedamawi - historical king
            "·ä¢·ã®·à±·àµ": "·ä≠·à≠·àµ·â∂·àµ",  # Jesus Christ
            "·àõ·à≠·ã´·àù": "·âÖ·ãµ·àµ·âµ ·àõ·à≠·ã´·àù",  # Saint Mary
            "·åà·â•·à≠·ä§·àç": "·àò·àã·ä≠ ·åà·â•·à≠·ä§·àç",  # Archangel Gabriel
            "·àö·ä´·ä§·àç": "·àò·àã·ä≠ ·àö·ä´·ä§·àç",  # Archangel Michael
            "·åà·äì": "·ã®·ä≠·à≠·àµ·â∂·àµ ·àç·ã∞·âµ",  # Christmas
            "·çã·à≤·ä´": "·ã®·âµ·äï·à≥·ä§ ·â†·ãì·àç",  # Easter
            "·ä•·äï·åÖ·â•": "·â£·àÖ·àã·ãä ·àµ·à≠·ãì·âµ",  # Traditional bread/hospitality
            "·â†·à®·ä®·âµ": "·âÖ·ã±·àµ ·â†·à®·ä®·âµ",  # Divine blessing
            "·àÉ·ã≠·àõ·äñ·âµ": "·âÖ·ã±·àµ ·àÉ·ã≠·àõ·äñ·âµ",  # Religion/faith
            "·ä†·ãç·àÆ·çì": "·ä†·àà·àù ·ä†·àÖ·åâ·à≠",  # Appropriate continent reference
            "·à∏·ãã": "·â≥·à™·ä´·ãä ·åç·ãõ·âµ",  # Historical province
            "·äï·åâ·à•": "·äï·åâ·à£·ãä ·àõ·ãï·à®·åç",  # Royal title
            "·ä•·äï·ã∞": "·ä†·äê·åª·åª·à™ ·âÉ·àç"  # Like/comparison word
        }
        
        # Terms that should never be associated with inappropriate concepts
        self.forbidden_associations = {
            "·â°·äì": [
                "addictive", "drug", "harmful", "dangerous", "toxic", "poison",
                "evil", "sin", "forbidden", "illegal", "bad", "negative"
            ],
            "·àò·àµ·âÄ·àç": [
                "decoration", "fashion", "jewelry", "ornament", "accessory",
                "style", "trend", "design", "art piece", "craft"
            ],
            "·âÄ·ã≥·àõ·ãä": [
                "dictator", "tyrant", "oppressor", "brutal", "cruel", "harsh",
                "mean", "bad", "evil", "wrong"
            ],
            "·ä¢·ã®·à±·àµ": [
                "myth", "fake", "false", "story", "character", "fiction",
                "ordinary", "human", "man", "person"
            ],
            "·àõ·à≠·ã´·àù": [
                "woman", "girl", "female", "ordinary", "common", "regular"
            ],
            "·åà·äì": [
                "party", "celebration", "fun", "entertainment", "commercial",
                "business", "shopping", "material"
            ],
            "·çã·à≤·ä´": [
                "party", "celebration", "fun", "entertainment", "holiday",
                "vacation", "break", "time off"
            ]
        }
        
        # Culturally sensitive topics requiring careful handling
        self.sensitive_topics = {
            "ethnicity": ["·ä¶·àÆ·àû", "·ä†·àõ·à´", "·âµ·åç·à¨", "·à≤·ã≥·àõ", "·ãà·àã·ã≠·â≥", "·à∂·àõ·àå", "·ä£·çã·à≠"],
            "politics": ["·àò·äï·åç·à•·âµ", "·çì·à≠·â≤", "·çñ·àà·â≤·ä´", "·â£·àà·àµ·àç·å£·äï", "·ã≤·àû·ä≠·à´·à≤"],
            "conflict": ["·åç·å≠·âµ", "·à∞·àã·àù", "·å¶·à≠·äê·âµ", "·àΩ·à≠", "·ä†·àà·àò·åç·â£·â£·âµ"],
            "history": ["·ã∞·à≠·åç", "·äï·åâ·à•", "·â∞·âÉ·ãã·àö", "·ä†·ãç·àÆ·çì", "·âÖ·äù", "·ä¢·å£·àä·ã´"]
        }
        
        # Dialect-specific variations for cultural terms
        self.dialect_variations = {
            "addis_ababa": {
                "·â°·äì": "·ã®·ä¢·âµ·ãÆ·åµ·ã´ ·â£·àÖ·àã·ãä ·àõ·àÖ·â†·à´·ãä ·à•·à≠·ãì·âµ",
                "·à∞·àã·àù": "·à∞·àã·àù ·ã≠·àÅ·äï·àç·äù"
            },
            "gojjam": {
                "·â°·äì": "·ã®·ä•·åç·ãö·ä†·â•·àî·à≠ ·àµ·å¶·â≥",
                "·à∞·àã·àù": "·à∞·àã·àù ·âµ·àÅ·äï·àç·äù"
            },
            "eritrea": {
                "·â°·äì": "·ãò·ä¢·âµ·ãÆ·åµ·ã´ ·â£·àÖ·àã·ãä ·àù·åç·â£·à≠",
                "·à∞·àã·àù": "·à∞·àã·àù ·ã©·àÄ·äê·àç·ä´"
            }
        }
        
        # Context-aware safety rules
        self.contextual_rules = {
            "religious": {
                "required_respect": ["·â°·äì", "·àò·àµ·âÄ·àç", "·åà·äì", "·çã·à≤·ä´"],
                "forbidden_casual": ["fun", "party", "entertainment"]
            },
            "historical": {
                "required_accuracy": ["·âÄ·ã≥·àõ·ãä", "·àÉ·ã≠·àà ·à•·àã·à¥", "·àã·àä·â†·àã"],
                "forbidden_modern": ["invention", "modern", "new"]
            }
        }
        
        # Positive cultural associations to encourage
        self.positive_associations = {
            "·â°·äì": [
                "·àõ·àÖ·â†·à´·ãä", "·â£·àÖ·àç", "·ãà·åç", "·ä†·äï·ãµ·äê·âµ", "·àò·åç·â£·â£·âµ", "·åì·ã∞·äù·äê·âµ",
                "·ä•·äï·åç·ã≥ ·â∞·âÄ·â£·ã≠·äê·âµ", "·àõ·àÖ·â†·à®·à∞·â•", "·ãà·äï·ãµ·àõ·àõ·âΩ·äê·âµ"
            ],
            "·àò·àµ·âÄ·àç": [
                "·âÖ·ã±·àµ", "·â†·à®·ä®·âµ", "·àÉ·ã≠·àõ·äñ·âµ", "·ä•·àù·äê·âµ", "·çç·âÖ·à≠", "·à∞·àã·àù",
                "·àù·àÖ·à®·âµ", "·â≥·àõ·äù·äê·âµ", "·ä≠·â•·à≠"
            ],
            "·ä¢·âµ·ãÆ·åµ·ã´": [
                "·â≥·à™·ä≠", "·â£·àÖ·àç", "·ãà·åç", "·âÖ·à≠·àµ", "·äê·çÉ·äê·âµ", "·ä©·à´·âµ",
                "·àç·ã©·äê·âµ", "·ä†·äï·ãµ·äê·âµ", "·ãç·â†·âµ"
            ]
        }
        
        # Compile regex patterns for efficient matching
        self._compile_patterns()
    
    def _compile_patterns(self):
        """Compile regex patterns for efficient text matching."""
        self.sacred_pattern = re.compile(
            '|'.join(re.escape(term) for term in self.sacred_terms.keys()),
            re.IGNORECASE
        )
        
        # Create patterns for forbidden words in multiple languages
        forbidden_words = set()
        for word_list in self.forbidden_associations.values():
            forbidden_words.update(word_list)
        
        self.forbidden_pattern = re.compile(
            '|'.join(re.escape(word) for word in forbidden_words),
            re.IGNORECASE
        )
    
    def check_cultural_safety(self, text: str) -> Tuple[bool, List[CulturalViolation]]:
        """
        Check if text complies with Amharic cultural safety guidelines.
        
        Args:
            text: Input text to check
            
        Returns:
            Tuple of (is_safe: bool, violations: List[CulturalViolation])
        """
        violations = []
        
        # Check for sacred term violations
        sacred_violations = self._check_sacred_terms(text)
        violations.extend(sacred_violations)
        
        # Check for sensitive topic handling
        sensitive_violations = self._check_sensitive_topics(text)
        violations.extend(sensitive_violations)
        
        # Check for cultural appropriateness
        appropriateness_violations = self._check_cultural_appropriateness(text)
        violations.extend(appropriateness_violations)
        
        is_safe = len(violations) == 0
        return is_safe, violations
    
    def _check_sacred_terms(self, text: str) -> List[CulturalViolation]:
        """Check for inappropriate use of sacred terms."""
        violations = []
        text_lower = text.lower()
        
        for sacred_term, description in self.sacred_terms.items():
            if sacred_term in text:
                # Check if any forbidden associations appear near the sacred term
                forbidden_words = self.forbidden_associations.get(sacred_term, [])
                
                for forbidden in forbidden_words:
                    if forbidden.lower() in text_lower:
                        # Check proximity (within 50 characters)
                        sacred_pos = text.find(sacred_term)
                        forbidden_pos = text_lower.find(forbidden.lower())
                        
                        if abs(sacred_pos - forbidden_pos) <= 50:
                            violations.append(CulturalViolation(
                                term=sacred_term,
                                violation_type="inappropriate_association",
                                context=f"'{sacred_term}' associated with '{forbidden}'",
                                severity="high"
                            ))
        
        return violations
    
    def _check_sensitive_topics(self, text: str) -> List[CulturalViolation]:
        """Check handling of culturally sensitive topics."""
        violations = []
        
        for topic_category, terms in self.sensitive_topics.items():
            for term in terms:
                if term in text:
                    # Check for inflammatory language nearby
                    inflammatory_words = [
                        "hate", "bad", "evil", "wrong", "stupid", "inferior",
                        "superior", "better", "worse", "fight", "enemy"
                    ]
                    
                    text_lower = text.lower()
                    for inflammatory in inflammatory_words:
                        if inflammatory in text_lower:
                            term_pos = text.find(term)
                            inflammatory_pos = text_lower.find(inflammatory)
                            
                            if abs(term_pos - inflammatory_pos) <= 30:
                                violations.append(CulturalViolation(
                                    term=term,
                                    violation_type="sensitive_topic_mishandling",
                                    context=f"Sensitive term '{term}' near inflammatory '{inflammatory}'",
                                    severity="medium"
                                ))
        
        return violations
    
    def _check_cultural_appropriateness(self, text: str) -> List[CulturalViolation]:
        """Check general cultural appropriateness."""
        violations = []
        
        # Check for overly casual treatment of formal cultural concepts
        formal_terms = ["·äï·åâ·à•", "·àò·äï·åç·à•·âµ", "·ä™·ã≥·äï", "·â†·ãì·àç", "·à•·à≠·ãì·âµ"]
        casual_words = ["fun", "party", "cool", "awesome", "whatever"]
        
        text_lower = text.lower()
        
        for formal_term in formal_terms:
            if formal_term in text:
                for casual in casual_words:
                    if casual in text_lower:
                        formal_pos = text.find(formal_term)
                        casual_pos = text_lower.find(casual)
                        
                        if abs(formal_pos - casual_pos) <= 40:
                            violations.append(CulturalViolation(
                                term=formal_term,
                                violation_type="inappropriate_tone",
                                context=f"Formal term '{formal_term}' treated casually with '{casual}'",
                                severity="low"
                            ))
        
        return violations
    
    def suggest_alternatives(self, text: str, violations: List[CulturalViolation]) -> Dict[str, str]:
        """
        Suggest culturally appropriate alternatives for problematic text.
        
        Args:
            text: Original text
            violations: List of violations found
            
        Returns:
            Dictionary mapping violation contexts to suggested alternatives
        """
        suggestions = {}
        
        for violation in violations:
            if violation.violation_type == "inappropriate_association":
                # Suggest positive associations instead
                term = violation.term
                if term in self.positive_associations:
                    positive_words = self.positive_associations[term]
                    suggestion = f"Consider associating '{term}' with positive concepts like: {', '.join(positive_words[:3])}"
                    suggestions[violation.context] = suggestion
            
            elif violation.violation_type == "sensitive_topic_mishandling":
                suggestions[violation.context] = "Use neutral, respectful language when discussing cultural groups and sensitive topics"
            
            elif violation.violation_type == "inappropriate_tone":
                suggestions[violation.context] = "Maintain respectful, formal tone when discussing cultural and religious concepts"
        
        return suggestions
    
    def get_cultural_context(self, term: str) -> str:
        """
        Get cultural context explanation for a term.
        
        Args:
            term: Amharic term to explain
            
        Returns:
            Cultural context explanation
        """
        if term in self.sacred_terms:
            return f"{term}: {self.sacred_terms[term]} - requires respectful treatment"
        
        # Check sensitive topics
        for category, terms in self.sensitive_topics.items():
            if term in terms:
                return f"{term}: {category} topic - handle with cultural sensitivity"
        
        return f"{term}: general term - follow standard cultural guidelines"
    
    def validate_generation(self, generated_text: str, input_context: str = "") -> Tuple[bool, str]:
        """
        Validate generated text for cultural safety.
        
        Args:
            generated_text: Text generated by the model
            input_context: Original input context
            
        Returns:
            Tuple of (is_valid: bool, feedback: str)
        """
        is_safe, violations = self.check_cultural_safety(generated_text)
        
        if is_safe:
            return True, "Text is culturally appropriate"
        
        feedback_parts = ["Cultural safety issues detected:"]
        
        for violation in violations:
            severity_emoji = {"low": "‚ö†Ô∏è", "medium": "üî∏", "high": "üö®"}
            emoji = severity_emoji.get(violation.severity, "‚ö†Ô∏è")
            feedback_parts.append(f"{emoji} {violation.context}")
        
        suggestions = self.suggest_alternatives(generated_text, violations)
        if suggestions:
            feedback_parts.append("\nSuggestions:")
            for context, suggestion in suggestions.items():
                feedback_parts.append(f"‚Ä¢ {suggestion}")
        
        return False, "\n".join(feedback_parts)