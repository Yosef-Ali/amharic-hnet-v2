#!/usr/bin/env python3
"""
Kaggle CLI Auto-Deploy - Simple & Robust
One-command deployment to Kaggle GPU with your credentials
"""

import os
import sys
import json
import subprocess
from pathlib import Path

class SimpleKaggleDeployer:
    """
    Simple, robust Kaggle CLI deployment.
    """
    
    def __init__(self):
        self.username = "yosefali2"
        self.dataset_name = "amharic-hnet-training"
        self.kernel_name = "amharic-gpu-training"
        
        print("üöÄ Kaggle Auto-Deploy for GPU Training")
        print(f"üë§ User: {self.username}")
        print(f"üéØ Target: 19M+ parameter model on Kaggle GPU")
    
    def ensure_kaggle_cli(self):
        """Ensure Kaggle CLI is available."""
        try:
            subprocess.run(['kaggle', '--version'], capture_output=True, check=True)
            print("‚úÖ Kaggle CLI ready")
            return True
        except:
            print("üì¶ Installing Kaggle CLI...")
            subprocess.run([sys.executable, '-m', 'pip', 'install', 'kaggle'], check=True)
            print("‚úÖ Kaggle CLI installed")
            return True
    
    def setup_api_key(self):
        """Setup Kaggle API credentials."""
        kaggle_dir = Path.home() / '.kaggle'
        kaggle_dir.mkdir(exist_ok=True)
        
        creds_file = kaggle_dir / 'kaggle.json'
        
        # Use existing credentials
        if Path('kaggle_credentials.json').exists():
            with open('kaggle_credentials.json') as f:
                creds = json.load(f)
            
            with open(creds_file, 'w') as f:
                json.dump(creds, f)
            
            os.chmod(creds_file, 0o600)
            print("‚úÖ API credentials configured")
            return True
        else:
            print("‚ùå No credentials found. Please add kaggle_credentials.json")
            return False
    
    def create_simple_training_script(self):
        """Create a simple, robust training script."""
        script = '''
# Kaggle GPU Training - Amharic H-Net Large Model
# Auto-generated for yosefali2

import torch
import torch.nn as nn
import torch.optim as optim
import time

print("üöÄ Amharic H-Net GPU Training Started")
print(f"GPU Available: {torch.cuda.is_available()}")

if torch.cuda.is_available():
    device = torch.device('cuda')
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")
else:
    device = torch.device('cpu')
    print("Using CPU")

# Large Model (19M+ parameters)
class AmharicModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.embedding = nn.Embedding(50000, 1024)
        self.transformer = nn.TransformerEncoder(
            nn.TransformerEncoderLayer(1024, 16, 4096, batch_first=True),
            num_layers=12
        )
        self.output = nn.Linear(1024, 50000)
    
    def forward(self, x):
        x = self.embedding(x)
        x = self.transformer(x)
        return self.output(x)

model = AmharicModel().to(device)
optimizer = optim.AdamW(model.parameters(), lr=2e-4)

print(f"Model parameters: {sum(p.numel() for p in model.parameters()):,}")

# Training loop
model.train()
start_time = time.time()
best_loss = float('inf')

for epoch in range(20):  # 20 epochs for demo
    epoch_loss = 0
    
    for batch in range(100):  # 100 batches per epoch
        # Synthetic data
        inputs = torch.randint(0, 50000, (8, 256), device=device)
        targets = torch.randint(0, 50000, (8, 256), device=device)
        
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = nn.CrossEntropyLoss()(outputs.view(-1, 50000), targets.view(-1))
        loss.backward()
        optimizer.step()
        
        epoch_loss += loss.item()
        
        if batch % 25 == 0:
            print(f"Epoch {epoch+1}, Batch {batch}: Loss={loss.item():.4f}")
    
    avg_loss = epoch_loss / 100
    print(f"Epoch {epoch+1}/20: Average Loss = {avg_loss:.4f}")
    
    # Save best model
    if avg_loss < best_loss:
        best_loss = avg_loss
        torch.save({
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'epoch': epoch,
            'loss': avg_loss
        }, 'best_model.pt')
        print(f"üíæ Best model saved! Loss: {avg_loss:.4f}")

training_time = time.time() - start_time

# Final save
torch.save({
    'model_state_dict': model.state_dict(),
    'training_time': training_time,
    'final_loss': avg_loss,
    'best_loss': best_loss
}, 'final_model.pt')

print(f"\nüèÜ Training Complete!")
print(f"Time: {training_time/60:.1f} minutes")
print(f"Best Loss: {best_loss:.4f}")
print(f"Models saved: best_model.pt, final_model.pt")
print("Ready for download!")
'''
        
        with open('main.py', 'w') as f:
            f.write(script)
        
        print("‚úÖ Training script created: main.py")
        return True
    
    def create_kernel_config(self):
        """Create kernel metadata."""
        config = {
            "id": f"{self.username}/{self.kernel_name}",
            "title": "Amharic H-Net GPU Training",
            "code_file": "main.py",
            "language": "python",
            "kernel_type": "script",
            "is_private": False,
            "enable_gpu": True,
            "enable_internet": True,
            "dataset_sources": [],
            "competition_sources": [],
            "kernel_sources": []
        }
        
        with open('kernel-metadata.json', 'w') as f:
            json.dump(config, f, indent=2)
        
        print("‚úÖ Kernel config created")
        return True
    
    def deploy_to_kaggle(self):
        """Deploy kernel to Kaggle."""
        print("üì§ Deploying to Kaggle...")
        
        try:
            # Push kernel
            result = subprocess.run(
                ['kaggle', 'kernels', 'push'],
                capture_output=True, text=True, check=True
            )
            
            print("‚úÖ Kernel deployed successfully!")
            
            # Extract kernel URL from output
            kernel_url = f"https://www.kaggle.com/code/{self.username}/{self.kernel_name}"
            print(f"üîó Kernel URL: {kernel_url}")
            
            return kernel_url
            
        except subprocess.CalledProcessError as e:
            print(f"‚ùå Deployment failed: {e.stderr}")
            return None
    
    def run_deployment(self):
        """Run complete deployment process."""
        print("üöÄ Starting Kaggle GPU Deployment")
        print("=" * 40)
        
        # Setup
        if not self.ensure_kaggle_cli():
            return False
        
        if not self.setup_api_key():
            return False
        
        # Create files
        self.create_simple_training_script()
        self.create_kernel_config()
        
        # Deploy
        kernel_url = self.deploy_to_kaggle()
        
        if kernel_url:
            print("\nüéâ Deployment Successful!")
            print(f"üîó Visit: {kernel_url}")
            print("\nüìã Next Steps:")
            print("1. Click the kernel URL above")
            print("2. Click 'Run' to start GPU training")
            print("3. Training will take ~30-60 minutes")
            print("4. Download models when complete")
            print("\n‚ö° GPU training will start automatically!")
            return True
        else:
            print("‚ùå Deployment failed")
            return False

def main():
    """Main function."""
    deployer = SimpleKaggleDeployer()
    
    print("\nüéØ Ready to deploy to Kaggle GPU?")
    confirm = input("Press Enter to continue or 'q' to quit: ").strip().lower()
    
    if confirm == 'q':
        print("üëã Deployment cancelled")
        return
    
    success = deployer.run_deployment()
    
    if success:
        print("\nüöÄ Your large model is now training on Kaggle GPU!")
    else:
        print("\n‚ùå Deployment failed. Check your credentials and try again.")

if __name__ == "__main__":
    main()