# !IMPORTANT - H-NET THEORY CRITICAL REFERENCE

## üö® MANDATORY READING FOR ALL SUB-AGENTS üö®

**THIS DOCUMENT MUST BE CONSULTED BEFORE ANY H-NET RELATED WORK**

---

## üß† TRUE H-NET ARCHITECTURE (ORIGINAL CHINESE IMPLEMENTATION)

**Source:** https://github.com/goombalab/hnet
**Research:** Completed analysis of dynamic chunking and hierarchical processing

### ‚ö†Ô∏è CRITICAL DISTINCTION: H-NET ‚â† TRADITIONAL TRANSFORMER

**H-Net is NOT:**
- ‚ùå Token-by-token generation
- ‚ùå Fixed morpheme patterns
- ‚ùå Byte-level processing
- ‚ùå Traditional transformer with morpheme detection
- ‚ùå Sequential autoregressive generation

**H-Net IS:**
- ‚úÖ Dynamic semantic chunking based on cosine similarity
- ‚úÖ Hierarchical processing of discovered chunks  
- ‚úÖ Chunk vocabulary creation through semantic boundaries
- ‚úÖ Generation through hierarchically transformed representations
- ‚úÖ Adaptive, context-aware segmentation

---

## üî• CORE H-NET COMPONENTS (MANDATORY IMPLEMENTATION)

### 1. DYNAMIC CHUNKING MECHANISM
```python
# FROM ORIGINAL: hnet/modules/dc.py
# Uses cosine similarity between consecutive hidden states
# Detects semantic boundaries dynamically
# Creates adaptive chunk vocabulary

def detect_boundaries(hidden_states):
    similarities = cosine_similarity(hidden_states[1:], hidden_states[:-1])
    boundary_probs = 0.5 * (1 - similarities)  # Low similarity = boundary
    return boundary_probs
```

### 2. HIERARCHICAL PROCESSING  
```python
# FROM ORIGINAL: ChunkLayer ‚Üí process chunks ‚Üí DeChunkLayer
# Transform (B, L, D) ‚Üí (B, L, D) through hierarchical backbone
# NOT flat token processing

def hierarchical_transform(embeddings, chunks):
    # Process at chunk level, not token level
    chunk_representations = process_chunks(embeddings, chunks)
    return hierarchically_transform(chunk_representations)
```

### 3. GENERATION APPROACH
```python
# FROM ORIGINAL: mixer_seq.py
# Uses hierarchically transformed representations
# Applies LM head to transformed states ‚Üí meaningful output
# NOT byte-level generation

def generate(input_ids):
    embeddings = embed(input_ids)
    hierarchical_output = hnet_backbone(embeddings)  # KEY: hierarchical transform
    logits = lm_head(hierarchical_output)
    return sample_from_logits(logits)
```

---

## üéØ AMHARIC H-NET SPECIFIC REQUIREMENTS

### CURRENT PROBLEM DIAGNOSIS:
- **INPUT:** "·ã≠·çà·àç·åã·àâ" (they want)
- **CURRENT OUTPUT:** "·ã≠·çà·àç·åã·àâ·êªo ·ïô·ïò·Ωô·Üêf“â“ô" (meaningless bytes)
- **REQUIRED OUTPUT:** "·ã≠·çà·àç·åã·àâ ·ãç·àÉ ·àò·å†·å£·âµ" (they want to drink water)

### ROOT CAUSE:
The current implementation is **NOT following H-Net theory**:
1. ‚ùå Using fixed morpheme patterns instead of dynamic chunking
2. ‚ùå Doing byte-level generation instead of hierarchical transformation
3. ‚ùå No chunk vocabulary creation for Amharic semantic units

### MANDATORY FIXES:

#### 1. REPLACE FIXED MORPHEME CHUNKER
```python
# WRONG (current):
class AmharicMorphemeChunker:
    self.verb_prefixes = ['·ã≠', '·àà', '·â†', ...]  # Fixed patterns
    
# CORRECT (H-Net theory):
class DynamicSemanticChunker:
    def detect_chunks(self, hidden_states):
        return cosine_similarity_boundaries(hidden_states)  # Dynamic detection
```

#### 2. IMPLEMENT HIERARCHICAL PROCESSING
```python
# WRONG (current):
def forward(self, x):
    boundaries = self.chunker(x)
    return transformer_process(x)  # Still flat processing
    
# CORRECT (H-Net theory):
def forward(self, x):
    chunks = self.dynamic_chunker(x)
    hierarchical_repr = self.process_hierarchically(x, chunks)
    return hierarchical_repr
```

#### 3. FIX GENERATION MECHANISM
```python
# WRONG (current):
def generate(self):
    for step in range(max_length):
        next_byte = sample_byte()  # Byte-level generation
        
# CORRECT (H-Net theory):
def generate(self):
    hierarchical_output = self.hnet_transform(input_embeddings)
    meaningful_output = self.lm_head(hierarchical_output)
    return meaningful_output
```

---

## üö® MANDATORY SUB-AGENT COMPLIANCE

### FOR ALL SUB-AGENTS:

#### BEFORE ANY H-NET WORK:
1. ‚úÖ **READ** this document completely
2. ‚úÖ **UNDERSTAND** H-Net ‚â† traditional transformer  
3. ‚úÖ **VERIFY** approach follows dynamic chunking theory
4. ‚úÖ **CONFIRM** no byte-level generation

#### FORBIDDEN APPROACHES:
- ‚ùå **NO** fixed morpheme patterns
- ‚ùå **NO** byte-by-byte generation
- ‚ùå **NO** traditional transformer modifications
- ‚ùå **NO** UTF-8 byte tricks
- ‚ùå **NO** autoregressive token sampling

#### REQUIRED APPROACHES:
- ‚úÖ **YES** dynamic semantic chunking (cosine similarity)
- ‚úÖ **YES** hierarchical chunk processing
- ‚úÖ **YES** chunk vocabulary creation
- ‚úÖ **YES** hierarchical transformation for generation
- ‚úÖ **YES** meaningful Amharic output

#### VERIFICATION QUESTIONS:
1. Does this approach use dynamic chunking based on semantic similarity?
2. Does this create adaptive chunk vocabulary?
3. Does this process hierarchically, not token-by-token?
4. Will this generate meaningful Amharic words, not random bytes?

**IF ANY ANSWER IS "NO" ‚Üí STOP AND REDESIGN**

---

## üéØ SUCCESS CRITERIA

### GOAL:
```
INPUT:  "·ã≠·çà·àç·åã·àâ" (they want)
OUTPUT: "·ã≠·çà·àç·åã·àâ ·ãç·àÉ ·àò·å†·å£·âµ" (they want to drink water)
```

### VALIDATION:
- ‚úÖ Uses dynamic semantic chunking
- ‚úÖ Creates Amharic chunk vocabulary
- ‚úÖ Processes hierarchically
- ‚úÖ Generates meaningful continuations
- ‚úÖ NO random byte sequences

---

## üìö REFERENCE IMPLEMENTATION

**Original H-Net:** https://github.com/goombalab/hnet
- `hnet/modules/dc.py` - Dynamic chunking mechanism
- `hnet/models/mixer_seq.py` - Generation approach
- Core principle: Transform (B, L, D) ‚Üí (B, L, D) hierarchically

---

## ‚ö†Ô∏è FINAL WARNING

**ANY SUB-AGENT THAT IGNORES THIS DOCUMENT AND IMPLEMENTS:**
- Fixed morpheme patterns
- Byte-level generation  
- Traditional transformer approaches
- Non-hierarchical processing

**WILL FAIL TO ACHIEVE MEANINGFUL AMHARIC GENERATION**

**THIS IS NOT NEGOTIABLE - H-NET THEORY MUST BE FOLLOWED EXACTLY**

---

**Document Status:** CRITICAL - MANDATORY COMPLIANCE
**Last Updated:** Current Session  
**Authority:** Primary Agent based on original H-Net research